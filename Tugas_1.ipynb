{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1BdVlzJ7Y2Sj52YeCWfjyWR1EETW5BZuI",
      "authorship_tag": "ABX9TyO5D7ojuUd7+w5FyoGQpsHQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfrizalDS/MachineLearning/blob/Jobsheet-4/Tugas_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tugas 1 (Opsional)**\n",
        "1.   Buatlah model klasifikasi dengan menggunakan SVM untuk data suara, voice.csv.\n",
        "\n",
        "1.   Buatlah model klasfikasi Multinomial Naive Bayes dengan ketentuan,\n",
        "\n",
        "  *   Menggunakan data spam.csv\n",
        "\n",
        "  *   Fitur CountVectorizer dengan mengaktifkan stop_words\n",
        "\n",
        "  *   Evaluasi hasilnya\n",
        "\n",
        "3.   Buatlah model klasfikasi Multinomial Naive Bayes dengan ketentuan,\n",
        "\n",
        "  *   Menggunakan data spam.csv\n",
        "\n",
        "  *   Fitur TF-IDF dengan mengaktifkan stop_words\n",
        "\n",
        "  *   Evaluasi hasilnya dan bandingkan dengan hasil pada Tugas no 2.\n",
        "\n",
        "  *   Berikan kesimpulan fitur mana yang terbaik pada kasus data spam.csv"
      ],
      "metadata": {
        "id": "2J44Sc__28dL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Nomor 1: SVM untuk Data Suara**\n",
        "\n"
      ],
      "metadata": {
        "id": "J3gtAL3a43bi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ArFBvzi2PPJ",
        "outputId": "ff5e69ce-df46-4f46-ab48-93064f976e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.96      0.99      0.98       297\n",
            "        male       0.99      0.97      0.98       337\n",
            "\n",
            "    accuracy                           0.98       634\n",
            "   macro avg       0.98      0.98      0.98       634\n",
            "weighted avg       0.98      0.98      0.98       634\n",
            "\n",
            "Akurasi SVM: 0.9763\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Membaca dataset\n",
        "voice_data = pd.read_csv('/content/drive/MyDrive/MachineLearning/JS 4/voice.csv')\n",
        "\n",
        "# Memisahkan fitur dan target\n",
        "X_voice = voice_data.drop(columns=['label'])\n",
        "y_voice = voice_data['label']\n",
        "\n",
        "# Membagi data menjadi set pelatihan dan pengujian\n",
        "X_train_voice, X_test_voice, y_train_voice, y_test_voice = train_test_split(X_voice, y_voice, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalisasi data\n",
        "scaler_voice = StandardScaler()\n",
        "X_train_scaled = scaler_voice.fit_transform(X_train_voice)\n",
        "X_test_scaled = scaler_voice.transform(X_test_voice)\n",
        "\n",
        "# Melatih model SVM\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_classifier.fit(X_train_scaled, y_train_voice)\n",
        "\n",
        "# Melakukan prediksi\n",
        "y_pred_voice = svm_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Evaluasi model\n",
        "print(classification_report(y_test_voice, y_pred_voice))\n",
        "print(f'Akurasi SVM: {accuracy_score(y_test_voice, y_pred_voice):.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Nomor 2: Multinomial Naive Bayes dengan CountVectorizer untuk Data Spam**"
      ],
      "metadata": {
        "id": "ybK6vyqD49CS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Membaca dataset spam\n",
        "spam_data = pd.read_csv('/content/drive/MyDrive/MachineLearning/JS 4/spam.csv', encoding='latin-1')\n",
        "\n",
        "# Mengambil kolom yang relevan\n",
        "spam_data = spam_data[['v1', 'v2']]\n",
        "spam_data.columns = ['label', 'message']\n",
        "spam_data['label'] = spam_data['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Memisahkan fitur dan target\n",
        "X_spam = spam_data['message']\n",
        "y_spam = spam_data['label']\n",
        "\n",
        "# Split data menjadi training dan test set\n",
        "X_train_spam, X_test_spam, y_train_spam, y_test_spam = train_test_split(X_spam, y_spam, test_size=0.2, random_state=42)\n",
        "\n",
        "# Menggunakan CountVectorizer dengan stop_words\n",
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "X_train_count = count_vectorizer.fit_transform(X_train_spam)\n",
        "X_test_count = count_vectorizer.transform(X_test_spam)\n",
        "\n",
        "# Melatih model Naive Bayes\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train_count, y_train_spam)\n",
        "\n",
        "# Prediksi dan evaluasi model\n",
        "y_pred_count = naive_bayes.predict(X_test_count)\n",
        "print(classification_report(y_test_spam, y_pred_count))\n",
        "print(f'Akurasi dengan CountVectorizer: {accuracy_score(y_test_spam, y_pred_count):.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yQimTd25LkF",
        "outputId": "e87538ad-692e-4385-8bb1-8d6b62d0f112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       965\n",
            "           1       0.96      0.92      0.94       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.97      0.96      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "Akurasi dengan CountVectorizer: 0.9839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Nomor 3: Multinomial Naive Bayes dengan TF-IDF untuk Data Spam**"
      ],
      "metadata": {
        "id": "PR0UFbHa49dL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# TF-IDF Vectorizer dengan stop_words\n",
        "tfidf_vectorizer_spam = TfidfVectorizer(stop_words='english')\n",
        "X_train_tfidf = tfidf_vectorizer_spam.fit_transform(X_train_spam)\n",
        "X_test_tfidf = tfidf_vectorizer_spam.transform(X_test_spam)\n",
        "\n",
        "# Model Naive Bayes dengan TF-IDF\n",
        "nb_tfidf_model = MultinomialNB()\n",
        "nb_tfidf_model.fit(X_train_tfidf, y_train_spam)\n",
        "\n",
        "# Prediksi dan evaluasi model\n",
        "y_pred_tfidf = nb_tfidf_model.predict(X_test_tfidf)\n",
        "print(classification_report(y_test_spam, y_pred_tfidf))\n",
        "print(f'Akurasi dengan TF-IDF: {accuracy_score(y_test_spam, y_pred_tfidf):.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqZSbrU_5MCd",
        "outputId": "b365790d-70c8-4da5-ff5f-5051b219d1a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       965\n",
            "           1       1.00      0.75      0.86       150\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.96      1115\n",
            "\n",
            "Akurasi dengan TF-IDF: 0.9668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Kesimpulan:**\n",
        "\n",
        "Berdasarkan hasil evaluasi, model klasifikasi Multinomial Naive Bayes dengan menggunakan CountVectorizer memberikan performa yang lebih baik dibandingkan model dengan TF-IDF. Model dengan CountVectorizer memiliki akurasi yang lebih tinggi dan lebih seimbang dalam mendeteksi pesan spam maupun non-spam. Meskipun TF-IDF menunjukkan keunggulan sedikit dalam precision untuk pesan spam, CountVectorizer memiliki recall yang lebih baik, yang berarti model ini lebih sensitif dalam mengidentifikasi pesan spam secara keseluruhan. Oleh karena itu, untuk kasus klasifikasi spam pada dataset ini, CountVectorizer merupakan fitur yang lebih efektif dan dapat diandalkan dibandingkan TF-IDF.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "odFaKtzj6WtV"
      }
    }
  ]
}